{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code playground: \n",
    "look here for example code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Use of Dates is Important\n",
    "\n",
    "Since we rely upon time series data to help regress two or more variables, store data and diversify the study, manipulating date variables is important. We will store sample data manipulations on dates in these workbooks.\n",
    "\n",
    "The underlying data is collected several times a minute from the Coinbase marketplace, where raddisco trades. These datun represent the high frequency metaorders (buy, sell) in the AVAX-USD token. Avalanche is a crypto project maintained by Mastercard and the former Cornell professor, Emin Gun Sirer. \n",
    "\n",
    "The structure of various files of data are stored with filenames, where dates are present. Traditional, human-read dates are common here. They imply that for a given day, certain variables were stored. There are several experiments: \n",
    "\n",
    "CAPS. These files store the volume and value of buy and sell orders, illustrating the flow-of-funds for a day. They typically represent one day or more in the market, and are collected each day, since August 11th, 2022.\n",
    "\n",
    "MEANSHIFT. These files represent the extent to which the distribution of market value skews, and helps map the degree to which the mean-shift away from a normed market shifts price. \n",
    "\n",
    "MATCH. These files represent the current algorithm results, at raddisco. These files store algorithmic choices on the mid point of the AVAX token, and represent how accurately current algorithms recommend trades. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the us indicator date to the filename type, using\n",
    "#https://pynative.com/python-datetime-format-strftime/#:~:text=Below%20are%20the%20character%20codes%20to%20format%20the,of%20the%20weekday.%20Like%2C%20Monday%2C%20Tuesday%20More%20items\n",
    "def convertxy():\n",
    "    from dateutil import parser\n",
    "    dt = parser.parse(\"Dec 21 2020  1:01PM\")\n",
    "    print(type(dt), dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take string, Wednesday, August 17, 2022\n",
    "#strip first three characters from first word to match file name by day\n",
    "#strip first three characters from second word, to arrive at comparable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(convertxy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how to access the limit order book files\n",
    "Supplying the name of the file will unlock the day's worth of data (MEANSHIFT, CAPS or MATCH). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thu Aug 11 2022 05:39:53 GMT-0700 (Pacific Daylight Time)-MEANSHIFT.csv\n",
    "x = pd.read_csv(\"lob_caps/Sat Sep 24 2022 11:10:07 GMT-0700 (Pacific Daylight Time)-MEANSHIFT.csv\")\n",
    "x.dtypes\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Economic Indicators Shape Market Activity\n",
    "\n",
    "here are the contents of the economic indicator announcement file. I typically refer to this variable set as Ia, or the announcment of an indicator. It implies an event, where a critical national economic statistic is announced. Markets tend to move before and after these events. \n",
    "\n",
    "For the sake of the study, one can imply that there exist two structures per Ia: the pre announcement buildup of metaorders (buy/sell), and the post announcement activity. This implies a buy up or sell off pre or post the event. A quadratic typology of pre and post market structures are likely mappable; we can study both the capitalization of sell (ask) and buy (bid) activity, the value of these orders, and the clumps of these orders. \n",
    "\n",
    "The indicator serves as a tool to help stimulate volatility, introduce causal features into the scenario, and create variations in price with clear cause. \n",
    "\n",
    "Later  in the study we will study each capitalization period, by day, then look for the corresponding Ia, in that day, if any. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndicators():\n",
    "    return pd.read_csv(\"usIndicatorsFall22-fulls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(getIndicators())\n",
    "print(type(getIndicators()), getIndicators().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = pd.read_csv(\"usIndicatorsFall22-fulls.csv\")\n",
    "t = ['date', 'time']\n",
    "ind[t].dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which economic indicators?\n",
    "\n",
    "and which fall within the data set?\n",
    "Currently, the following annouced indicators are studied. They are chosen due to their critical importance and understood impact on public markets. \n",
    "\n",
    "If you combine the factors from the getIndicators() function above, you could study the trend of the forecast indicator, in conjunction with the capitalization rates in markets. There is of course, a spread between forecast, consensus and actual values within the indicator, which form its own trend. \n",
    "\n",
    "The data set allows for each major indicator to be observed through several months, as it is forecast and announced. Given that each indicator possesses a life of its own, they illustrate the US's economic activity through two quarters, and how that public pessimism (or lack thereof) is reflected in the cryptocurrency metaorder set. \n",
    "\n",
    "Other financial products can be studied within this perspective. If you took the annoucement trend alongside a galaxy of equities, for example, the price trend could be studied, alongside permutations in the indicator, or a set. \n",
    "\n",
    "The study also encourages a multivariate study. The combination of factors is completely available, as scenarios in employment, ISM and inflation become visbile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ind['indicator'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### study one indicator\n",
    "supply the name of an indicator from the list, above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind[ind['indicator'] == 'core inflation rate yoy']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loop all indicators and load one df per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ind['indicator'].unique():\n",
    "    print(i)\n",
    "    print(ind[ind['indicator'] == i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gather all the LOB data files per announcement\n",
    "\n",
    "Since the coup de grace involes pinnning down the indicator with the market's metaorders, integrating the indicators with capitalization is key. Below various data-prep steps are taken to combine the day of the Ia with the corresponding market order flow. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concatenating folder path to filename:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCSV(type, fileName):\n",
    "    if type == \"caps\":\n",
    "        sl = \"./lob_caps/\"\n",
    "        loc= sl+ fileName #+ \"-CAPS.csv\"\n",
    "    df = pd.read_csv(loc)\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get limit order book for a date string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlob(csv):\n",
    "        print(\"GETTING LOB FILE FOR: csv named \",csv)\n",
    "        csv = \"lob_caps/\" + csv\n",
    "        df = pd.read_csv(csv)\n",
    "            # print(\"\\tfor \", type, df.columns)\n",
    "        return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get CAPS for indicator date\n",
    "Searches for filenames of a certain date. Returns a dataframe from the dated file, with the elaborated date data. This example searches and retrieves a CAPS file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def getCAPSByDateAndType(date, type, edt ):  #returns a dict, date + df caps for that date, then extended date and time\n",
    "                                # print(\"for type, \", type)\n",
    "    for root, dirs, files in os.walk(\".\"):\n",
    "        for filename in files:\n",
    "            if date in filename :\n",
    "                if type in filename:\n",
    "                    print(\"GET CAPS FOR: \", date  , \" : \", filename)\n",
    "                                 # print(\"returning, \", filename )\n",
    "                    obj = {\"date\":date, \"df\":getlob(filename), \"time\":edt}\n",
    "                                # print(\"getting caps from  \", filename ,obj)\n",
    "                    return obj\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# primary study entry point\n",
    "Iterates indicator file, returns data frame per indicator announcement, based on the type of data you wish. Supply argument \"CAPS\" to get capitalization data. \n",
    "\n",
    "will grab the indicator first, then grab the capitalization data on the day of that indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterateByType(type):\n",
    "    # print(\"for type, \", type)\n",
    "    data = getIndicators() #indicators file read, access all indicator data per event/announcement\n",
    "    result = []\n",
    "    for row, val in data.iterrows():\n",
    "        s1 = val['date'].replace(','  , '')\n",
    "        ss = s1.split(\" \")\n",
    "        day  = ss[0][0:3]\n",
    "        mon = ss[1][0:3]\n",
    "        num = ss[2]\n",
    "        hr = val['time']\n",
    "        if int(num) <10:\n",
    "            num = \"0\"+num\n",
    "        yr = ss[3]\n",
    "        l = day + \" \" + mon + \" \" + num #+ \" \" + hr\n",
    "        extendedDateTime = day + \" \" + mon + \" \" + num + \" \" + hr + \" \" +yr\n",
    "        print(\"FOR INDICATOR, DATED: \",extendedDateTime)\n",
    "        result.append(getCAPSByDateAndType(l, type, extendedDateTime)) #returns df/caps and the date associated    \n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## study one: how does the announcement impact the accumulation of the commodity?\n",
    "\n",
    "one direction to take is a regression analysis of types of orders (buy or sell) with the resulting price. Does buy order flow impact the price of something more than the sell activity?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### study correlations\n",
    "acquire data from the caps files related to an indicator. this feature prints out the end result of integrating indicator and caps files\n",
    "\n",
    "output appears at the close of the exhibit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def studyCorrelations(cArr):\n",
    "    print(len(cArr))\n",
    "\n",
    "    for i in range(len(cArr)):\n",
    "        print(cArr[i][\"date\"], \"CAPS data: \")\n",
    "        print(cArr[i][\"corrDf\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "help the announcement file coordinate with the .csv of CAPS, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertMo(month):\n",
    "    if month ==\"Aug\":\n",
    "        return \"08\"\n",
    "    if month == \"Sep\":\n",
    "        return \"09\"\n",
    "    if month == \"Oct\":\n",
    "        return \"10\"\n",
    "    if month == \"Nov\":\n",
    "        return \"11\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "express the csv file's day as an epoch, an integer value representing the milliseconds since 1970. This epoch format is used inside the CAPS file and others to capture the second when capitalizations took place. The epoch is a cheap way to store time series as a single integer. \n",
    "\n",
    "However, the date of the csv (in the filename) must be translated into an epoch in order to correctly sync with a day of capitalizatoin data. A better study would be to make all dates in one format, but advantages exist for epochs, as they can do very simply and fast arithmetic, though they lack readability by people. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "def convertIndicatorDateToEpoch(original):\n",
    "    # print(\"original \", original) #Thu Aug 11 4:30 AM 2022\n",
    "    re =time.strptime(original, \"%a %b %d %I:%M %p %Y\")\n",
    "    ep = time.mktime(re)\n",
    "    # print(\"TS \", int(ep))   #1660311116579\n",
    "    return int(ep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### joining announcement data and capitalization data\n",
    "what was the capitalization before and after an announcement?\n",
    "\n",
    "a key integration step, which we'll use often\n",
    "\n",
    "in early iterations of this step, the array of announcements was used to locate proper day data. In the future, the opposite will take place, to study patterns across many days. We will likely iterate all capitalizations, then for each day of fund flows, look for a possible announcement, and study the markets on announcement days. \n",
    "\n",
    "This branches the study into two directions: \n",
    "* forms a correlation matrix between order types, order volumes, values and pricing [hot study, needs to be done!]\n",
    "* a visualization workbench for capitalization, which to date only exists for buy orders and mid point price. \n",
    "\n",
    "no pressure or anytyhing, but simply doing any one of the above studies will likely satisfy the M1 deliverable. What if we knew which variable had the greatest association with price? Its UNKNOWN heretofore, and is worth a great deal to the hedge fund industry [CAPTAIN JACK TREASURE CHEST]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from time import gmtime, strptime\n",
    "def demarcateByAnnounceTime():\n",
    "    obj = iterateByType(\"CAPS\")\n",
    "    # print(obj)#  , obj[\"df\"])\n",
    "    corrArray = []\n",
    "    # visualizeAnnoucementBuild = []\n",
    "    for i in range(len(obj)):\n",
    "        if obj[i] is not None:\n",
    "            # print(obj[i][\"df\"][\"mp\"].head(2))\n",
    "            # print(type(obj[i][\"df\"].corr()))\n",
    "            #CORRELATE EACH COLUMN TO ROW, FORM ONE MATRIX PER DAY OF DATA\n",
    "            corrMatrix = obj[i][\"df\"].corr()\n",
    "            date = obj[i][\"time\"]\n",
    "            indEpoch = convertIndicatorDateToEpoch(date)#.split(\" \") # turn this to epoch Mon Aug 01 6:00 AM\n",
    "            buildDict = {\"date\":date , \"indicatorAnnouncementEpoch\":indEpoch}\n",
    "            # visualizeAnnoucementBuild.append(buildDict) #date of announcement and its epoch value\n",
    "            dict = {\"corrDf\": corrMatrix, \"date\":date }\n",
    "            corrArray.append(dict)\n",
    "    # visualizeAnnoucementBuilds(visualizeAnnoucementBuild)\n",
    "    studyCorrelations(corrArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demarcateByAnnounceTime()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iterate Indicator dataframe by index**\n",
    "\n",
    "provide an index location in the indicator dataframe, and get back the indicator, with information"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retrieve all csv data per row in indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read into ind df, get time of the release, use date to retrieve a file name, using ls array, find day string in that array, use result to grab a file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iterating economic announcements\n",
    "you can supply an index value to look up an announcement's day data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterateIndforIndex(index):\n",
    "    frame = ind.loc[index]\n",
    "    return frame\n",
    "\n",
    "t = iterateIndforIndex(0)\n",
    "t.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualization workbench: associating a key variable versus midpoint price\n",
    "TODO: for every day of capitalization, locate whether an Ia happened that day. What was the impact before and after the Ia? \n",
    "* YET ANOTHER CAPTAIN JACK PROBLEM TO SOLVE\n",
    "* for each day of capitalization (CAPS file), look for an announcement. Take the epoch value of the announcement date, and plug it in as an axvline, in the final 3 lines of the following script, this will demarcate the pre and post capitalization events, pertaining to an Ia. \n",
    "* the below code will help us to EDA the metaorder activity typical to the time before an Ia, then after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def demarcateByAnnounceTime():\n",
    "    dfArray = iterateByType(\"CAPS\")\n",
    "    # print(\"CAPS array: \\n\",len(dfArray))\n",
    "    #now iterate the array, and per caps result, draw a chart with a line and the caps series(53)\n",
    "    for i in range(len(dfArray)):\n",
    "        if i > 9:\n",
    "            if isinstance(dfArray[i], dict):\n",
    "                # print(i, \"iterated 1, \",  dfArray[i], \"iterated 2, \", type(dfArray[i])) #every item is a dict\n",
    "                \n",
    "                print(\"start time: \", dfArray[i][\"df\"][\"time\"].min())\n",
    "                print(\"end time: \", dfArray[i][\"df\"][\"time\"].max())\n",
    "                print(\"date of data: \", dfArray[i][\"date\"], \"\\n\")\n",
    "                \n",
    "                data1 = dfArray[i][\"df\"]['mp']\n",
    "                data2 = dfArray[i][\"df\"]['bc']\n",
    "                t= dfArray[i][\"df\"]['time']\n",
    "                ai = dfArray[i][\"time\"]\n",
    "                fig, ax1 = plt.subplots()\n",
    "                tt = i + 1\n",
    "                if isinstance(dfArray[tt][\"time\"], str):\n",
    "                    indEpoch = convertIndicatorDateToEpoch(dfArray[tt][\"time\"])#.split(\" \") # turn this to epoch Mon Aug 01 6:00 AM\n",
    "                    print(\"Announcement time: \",indEpoch)\n",
    "                color = 'tab:red'\n",
    "                ax1.set_xlabel('time (s)')\n",
    "                ax1.set_ylabel('price, AVAX', color=color)\n",
    "                ax1.plot(t, data1, color=color)\n",
    "                ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "                ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "                color = 'tab:blue'\n",
    "                ax2.set_ylabel('buy capitalization', color=color)  # we already handled the x-label with ax1\n",
    "                ax2.plot(t, data2, color=color)\n",
    "                ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "                fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "                e = dfArray[i][\"df\"]['time'].loc[0]   #datetime.datetime.fromtimestamp(\n",
    "                comb = e ,\" Buy Cap versus Price\" #.strftime('%m-%d')\n",
    "                # plt.close()\n",
    "                plt.title(comb)\n",
    "                #add vertical line at x=4\n",
    "                # if indEpoch:\n",
    "                #     plt.axvline(x=indEpoch, color='black', linestyle='-')\n",
    "                plt.show()\n",
    "                plt.close()        \n",
    "demarcateByAnnounceTime()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorizing the Volatility pre and post announcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR INDICATOR, DATED:  Mon Aug 01 6:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Tue Aug 02 6:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Wed Aug 03 6:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Thu Aug 04 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Fri Aug 05 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Wed Aug 10 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Wed Aug 10 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Thu Aug 11 4:30 AM 2022\n",
      "GET CAPS FOR:  Thu Aug 11  :  Thu Aug 11 2022 05:39:53 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Thu Aug 11 2022 05:39:53 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Fri Aug 12 6:00 AM 2022\n",
      "GET CAPS FOR:  Fri Aug 12  :  Fri Aug 12 2022 06:31:51 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Fri Aug 12 2022 06:31:51 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Tue Aug 16 4:30 AM 2022\n",
      "GET CAPS FOR:  Tue Aug 16  :  Tue Aug 16 2022 05:46:44 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Tue Aug 16 2022 05:46:44 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Wed Aug 17 4:30 AM 2022\n",
      "GET CAPS FOR:  Wed Aug 17  :  Wed Aug 17 2022 10:16:57 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Wed Aug 17 2022 10:16:57 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Wed Aug 17 10:00 AM 2022\n",
      "GET CAPS FOR:  Wed Aug 17  :  Wed Aug 17 2022 10:16:57 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Wed Aug 17 2022 10:16:57 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Wed Aug 24 4:30 AM 2022\n",
      "GET CAPS FOR:  Wed Aug 24  :  Wed Aug 24 2022 08:44:06 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Wed Aug 24 2022 08:44:06 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Fri Aug 26 4:30 AM 2022\n",
      "GET CAPS FOR:  Fri Aug 26  :  Fri Aug 26 2022 06:27:17 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Fri Aug 26 2022 06:27:17 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Fri Aug 26 4:30 AM 2022\n",
      "GET CAPS FOR:  Fri Aug 26  :  Fri Aug 26 2022 06:27:17 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Fri Aug 26 2022 06:27:17 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Fri Aug 26 6:00 AM 2022\n",
      "GET CAPS FOR:  Fri Aug 26  :  Fri Aug 26 2022 06:27:17 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Fri Aug 26 2022 06:27:17 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Tue Aug 30 6:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Thu Sep 01 6:00 AM 2022\n",
      "GET CAPS FOR:  Thu Sep 01  :  Thu Sep 01 2022 06:40:31 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Thu Sep 01 2022 06:40:31 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Fri Sep 02 4:30 AM 2022\n",
      "GET CAPS FOR:  Fri Sep 02  :  Fri Sep 02 2022 05:51:12 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Fri Sep 02 2022 05:51:12 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Tue Sep 06 6:00 AM 2022\n",
      "GET CAPS FOR:  Tue Sep 06  :  Tue Sep 06 2022 05:10:06 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Tue Sep 06 2022 05:10:06 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Wed Sep 07 4:30 AM 2022\n",
      "GET CAPS FOR:  Wed Sep 07  :  Wed Sep 07 2022 07:36:51 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Wed Sep 07 2022 07:36:51 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Wed Sep 14 4:30 AM 2022\n",
      "GET CAPS FOR:  Wed Sep 14  :  Wed Sep 14 2022 07:03:52 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Wed Sep 14 2022 07:03:52 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Thu Sep 15 4:30 AM 2022\n",
      "GET CAPS FOR:  Thu Sep 15  :  Thu Sep 15 2022 06:21:27 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Thu Sep 15 2022 06:21:27 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Fri Sep 16 6:00 AM 2022\n",
      "GET CAPS FOR:  Fri Sep 16  :  Fri Sep 16 2022 05:38:37 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Fri Sep 16 2022 05:38:37 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Tue Sep 20 4:30 AM 2022\n",
      "GET CAPS FOR:  Tue Sep 20  :  Tue Sep 20 2022 05:53:56 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Tue Sep 20 2022 05:53:56 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Wed Sep 21 10:00 AM 2022\n",
      "GET CAPS FOR:  Wed Sep 21  :  Wed Sep 21 2022 11:55:57 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Wed Sep 21 2022 11:55:57 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Wed Sep 21 10:00 AM 2022\n",
      "GET CAPS FOR:  Wed Sep 21  :  Wed Sep 21 2022 11:55:57 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Wed Sep 21 2022 11:55:57 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Tue Sep 27 4:30 AM 2022\n",
      "GET CAPS FOR:  Tue Sep 27  :  Tue Sep 27 2022 07:35:37 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Tue Sep 27 2022 07:35:37 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Fri Sep 30 4:30 AM 2022\n",
      "GET CAPS FOR:  Fri Sep 30  :  Fri Sep 30 2022 06:15:52 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Fri Sep 30 2022 06:15:52 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Fri Sep 30 4:30 AM 2022\n",
      "GET CAPS FOR:  Fri Sep 30  :  Fri Sep 30 2022 06:15:52 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Fri Sep 30 2022 06:15:52 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Mon Oct 03 6:00 AM 2022\n",
      "GET CAPS FOR:  Mon Oct 03  :  Mon Oct 03 2022 06:30:58 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Mon Oct 03 2022 06:30:58 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Tue Oct 04 6:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Wed Oct 05 4:30 AM 2022\n",
      "GET CAPS FOR:  Wed Oct 05  :  Wed Oct 05 2022 07:37:11 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Wed Oct 05 2022 07:37:11 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Wed Oct 05 6:00 AM 2022\n",
      "GET CAPS FOR:  Wed Oct 05  :  Wed Oct 05 2022 07:37:11 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Wed Oct 05 2022 07:37:11 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Fri Oct 07 4:30 AM 2022\n",
      "GET CAPS FOR:  Fri Oct 07  :  Fri Oct 07 2022 10:19:43 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Fri Oct 07 2022 10:19:43 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Wed Oct 12 4:30 AM 2022\n",
      "GET CAPS FOR:  Wed Oct 12  :  Wed Oct 12 2022 07:36:21 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Wed Oct 12 2022 07:36:21 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Wed Oct 12 10:00 AM 2022\n",
      "GET CAPS FOR:  Wed Oct 12  :  Wed Oct 12 2022 07:36:21 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Wed Oct 12 2022 07:36:21 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Thu Oct 13 4:30 AM 2022\n",
      "GET CAPS FOR:  Thu Oct 13  :  Thu Oct 13 2022 06:54:58 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Thu Oct 13 2022 06:54:58 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Thu Oct 13 4:30 AM 2022\n",
      "GET CAPS FOR:  Thu Oct 13  :  Thu Oct 13 2022 06:54:58 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Thu Oct 13 2022 06:54:58 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Fri Oct 14 4:30 AM 2022\n",
      "GET CAPS FOR:  Fri Oct 14  :  Fri Oct 14 2022 10:56:42 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Fri Oct 14 2022 10:56:42 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Fri Oct 14 6:00 AM 2022\n",
      "GET CAPS FOR:  Fri Oct 14  :  Fri Oct 14 2022 10:56:42 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Fri Oct 14 2022 10:56:42 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Wed Oct 19 4:30 AM 2022\n",
      "GET CAPS FOR:  Wed Oct 19  :  Wed Oct 19 2022 08:15:42 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Wed Oct 19 2022 08:15:42 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Thu Oct 27 4:30 AM 2022\n",
      "GET CAPS FOR:  Thu Oct 27  :  Thu Oct 27 2022 07:39:06 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Thu Oct 27 2022 07:39:06 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Fri Oct 28 4:30 AM 2022\n",
      "GET CAPS FOR:  Fri Oct 28  :  Fri Oct 28 2022 05:12:18 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Fri Oct 28 2022 05:12:18 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Fri Oct 28 4:30 AM 2022\n",
      "GET CAPS FOR:  Fri Oct 28  :  Fri Oct 28 2022 05:12:18 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Fri Oct 28 2022 05:12:18 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Tue Nov 01 6:00 AM 2022\n",
      "GET CAPS FOR:  Tue Nov 01  :  Tue Nov 01 2022 06:31:11 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Tue Nov 01 2022 06:31:11 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Tue Nov 01 6:00 AM 2022\n",
      "GET CAPS FOR:  Tue Nov 01  :  Tue Nov 01 2022 06:31:11 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Tue Nov 01 2022 06:31:11 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Wed Nov 02 10:30 AM 2022\n",
      "GET CAPS FOR:  Wed Nov 02  :  Wed Nov 02 2022 07:19:43 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Wed Nov 02 2022 07:19:43 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Thu Nov 03 4:30 AM 2022\n",
      "GET CAPS FOR:  Thu Nov 03  :  Thu Nov 03 2022 08:01:55 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Thu Nov 03 2022 08:01:55 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Fri Nov 04 4:30 AM 2022\n",
      "GET CAPS FOR:  Fri Nov 04  :  Fri Nov 04 2022 08:56:11 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Fri Nov 04 2022 08:56:11 GMT-0700 (Pacific Daylight Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Thu Nov 10 5:30 AM 2022\n",
      "GET CAPS FOR:  Thu Nov 10  :  Thu Nov 10 2022 07:14:14 GMT-0800 (Pacific Standard Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Thu Nov 10 2022 07:14:14 GMT-0800 (Pacific Standard Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Thu Nov 10 5:30 AM 2022\n",
      "GET CAPS FOR:  Thu Nov 10  :  Thu Nov 10 2022 07:14:14 GMT-0800 (Pacific Standard Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Thu Nov 10 2022 07:14:14 GMT-0800 (Pacific Standard Time)-CAPS.csv\n",
      "FOR INDICATOR, DATED:  Fri Nov 11 7:00 AM 2022\n",
      "GET CAPS FOR:  Fri Nov 11  :  Fri Nov 11 2022 07:08:40 GMT-0800 (Pacific Standard Time)-CAPS.csv\n",
      "GETTING LOB FILE FOR: csv named  Fri Nov 11 2022 07:08:40 GMT-0800 (Pacific Standard Time)-CAPS.csv\n",
      "indicator time:  1660217400 \n",
      " min:  1660221600292 max:  1660310239748\n",
      "indicator time:  1660309200 \n",
      " min:  1660311116579 max:  1660415046770\n",
      "indicator time:  1660649400 \n",
      " min:  1660654009157 max:  1660756532340\n",
      "indicator time:  1660735800 \n",
      " min:  1660756621563 max:  1660842042460\n",
      "indicator time:  1660755600 \n",
      " min:  1660756621563 max:  1660842042460\n",
      "indicator time:  1661340600 \n",
      " min:  1661355849950 max:  1661448267706\n",
      "indicator time:  1661513400 \n",
      " min:  1661520441572 max:  1661635166818\n",
      "indicator time:  1661513400 \n",
      " min:  1661520441572 max:  1661635166818\n",
      "indicator time:  1661518800 \n",
      " min:  1661520441572 max:  1661635166818\n",
      "indicator time:  1662037200 \n",
      " min:  1662039636072 max:  1662122445286\n",
      "indicator time:  1662118200 \n",
      " min:  1662123076541 max:  1662211743740\n",
      "indicator time:  1662469200 \n",
      " min:  1662466210194 max:  1662511998693\n",
      "indicator time:  1662550200 \n",
      " min:  1662561416530 max:  1662650276632\n",
      "indicator time:  1663155000 \n",
      " min:  1663164236672 max:  1663247227945\n",
      "indicator time:  1663241400 \n",
      " min:  1663248091774 max:  1663331309729\n",
      "indicator time:  1663333200 \n",
      " min:  1663331923149 max:  1663421950665\n",
      "indicator time:  1663673400 \n",
      " min:  1663678440335 max:  1663785897665\n",
      "indicator time:  1663779600 \n",
      " min:  1663786562232 max:  1663849989720\n",
      "indicator time:  1663779600 \n",
      " min:  1663786562232 max:  1663849989720\n",
      "indicator time:  1664278200 \n",
      " min:  1664289343672 max:  1664371038555\n",
      "indicator time:  1664537400 \n",
      " min:  1664543756415 max:  1664637777834\n",
      "indicator time:  1664537400 \n",
      " min:  1664543756415 max:  1664637777834\n",
      "indicator time:  1664802000 \n",
      " min:  1664803863360 max:  1664978989459\n",
      "indicator time:  1664969400 \n",
      " min:  1664980636066 max:  1665161668660\n",
      "indicator time:  1664974800 \n",
      " min:  1664980636066 max:  1665161668660\n",
      "indicator time:  1665142200 \n",
      " min:  1665163187745 max:  1665239597769\n",
      "indicator time:  1665574200 \n",
      " min:  1665585385785 max:  1665669195061\n",
      "indicator time:  1665594000 \n",
      " min:  1665585385785 max:  1665669195061\n",
      "indicator time:  1665660600 \n",
      " min:  1665669302426 max:  1665769275366\n",
      "indicator time:  1665660600 \n",
      " min:  1665669302426 max:  1665769275366\n",
      "indicator time:  1665747000 \n",
      " min:  1665770207034 max:  1665848949103\n",
      "indicator time:  1665752400 \n",
      " min:  1665770207034 max:  1665848949103\n",
      "indicator time:  1666179000 \n",
      " min:  1666195760061 max:  1666275760684\n",
      "indicator time:  1666870200 \n",
      " min:  1666881550370 max:  1666958724790\n",
      "indicator time:  1666956600 \n",
      " min:  1666959142055 max:  1667082109406\n",
      "indicator time:  1666956600 \n",
      " min:  1666959142055 max:  1667082109406\n",
      "indicator time:  1667307600 \n",
      " min:  1667309475693 max:  1667398185044\n",
      "indicator time:  1667307600 \n",
      " min:  1667309475693 max:  1667398185044\n",
      "indicator time:  1667410200 \n",
      " min:  1667398787547 max:  1667486779339\n",
      "indicator time:  1667475000 \n",
      " min:  1667487719720 max:  1667576510332\n",
      "indicator time:  1667561400 \n",
      " min:  1667577375004 max:  1667663298398\n",
      "indicator time:  1668087000 \n",
      " min:  1668093258813 max:  1668178634089\n",
      "indicator time:  1668087000 \n",
      " min:  1668093258813 max:  1668178634089\n",
      "indicator time:  1668178800 \n",
      " min:  1668179324508 max:  1668266770467\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from time import gmtime, strptime\n",
    "def getPreAndPostIa():\n",
    "    obj = iterateByType(\"CAPS\")\n",
    "    # print(obj)#  , obj[\"df\"])\n",
    "    for i in range(len(obj)):\n",
    "        if obj[i] is not None:\n",
    "            # print(obj[i][\"df\"][\"mp\"].head(2))\n",
    "            # print(type(obj[i][\"df\"].corr()))\n",
    "            #CORRELATE EACH COLUMN TO ROW, FORM ONE MATRIX PER DAY OF DATA\n",
    "            \n",
    "            date = obj[i][\"time\"]\n",
    "            indEpoch = convertIndicatorDateToEpoch(date)#.split(\" \") # turn this to epoch Mon Aug 01 6:00 AM\n",
    "            buildDict = {\"date\":date , \"indicatorAnnouncementEpoch\":indEpoch}\n",
    "            minDate = obj[i][\"df\"][\"time\"].min()\n",
    "            maxDate = obj[i][\"df\"][\"time\"].max()\n",
    "            print(\"indicator time: \", indEpoch,\"\\n\", \"min: \", minDate, \"max: \", maxDate)\n",
    "            if indEpoch in range(minDate, maxDate):\n",
    "                print(\"for indicator time, \" ,date)\n",
    "            # visualizeAnnoucementBuild.append(buildDict) #date of announcement and its epoch value\n",
    "            # dict = {\"corrDf\": corrMatrix, \"date\":date }\n",
    "    # visualizeAnnoucementBuilds(visualizeAnnoucementBuild)\n",
    "    \n",
    "getPreAndPostIa() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3e22fbf24de83286095bc3b5210627f6bc981651d6552786864646d5785863e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
