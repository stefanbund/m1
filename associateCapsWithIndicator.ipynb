{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iterate all files related to CAPS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### csv file list and endFrame\n",
    "endFrame: the global data frame\n",
    "csvFileList: the list of all csv files we must search by\n",
    "acquire .csv files in the local directory, by type (caps, match, etc) then compile into a global dataframe, containing the entire sequence of data points. This is several months of high frequency intake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'lob_caps/integrateIndicatorWithCAPS.ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/stefanbund/ubuntu/m1/iterateAllCps.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/stefanbund/ubuntu/m1/iterateAllCps.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     csv \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlob_caps/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m filename\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/stefanbund/ubuntu/m1/iterateAllCps.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# print(csv)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/stefanbund/ubuntu/m1/iterateAllCps.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(csv, index_col\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, header\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/stefanbund/ubuntu/m1/iterateAllCps.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     li\u001b[39m.\u001b[39mappend(df)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/stefanbund/ubuntu/m1/iterateAllCps.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m endFrame \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(li, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m#end frame contains all data\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/pandas/io/parsers/readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 934\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1219\u001b[0m     f,\n\u001b[1;32m   1220\u001b[0m     mode,\n\u001b[1;32m   1221\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1223\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1224\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1225\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1226\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1227\u001b[0m )\n\u001b[1;32m   1228\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/pandas/io/common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    787\u001b[0m             handle,\n\u001b[1;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    792\u001b[0m         )\n\u001b[1;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lob_caps/integrateIndicatorWithCAPS.ipynb'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#https://stackoverflow.com/a/21232849 model \n",
    "def getCAPSByDateAndType(type):  #returns a dict, date + df caps for that date, then extended date and time\n",
    "                                # print(\"for type, \", type)\n",
    "    ret = []\n",
    "    for root, dirs, files in os.walk(\".\"):\n",
    "        for filename in files:\n",
    "            if type in filename:\n",
    "                # print(\"CAPS file, \", filename)\n",
    "                ret.append(filename)\n",
    "    return ret\n",
    "\n",
    "csvFileList = getCAPSByDateAndType(\"CAPS\") #iterate this array to dip into each csv, later on\n",
    "li = []                         #form the endFrame / global data frame around this array\n",
    "for filename in csvFileList:\n",
    "    csv = \"lob_caps/\" + filename\n",
    "    # print(csv)\n",
    "    df = pd.read_csv(csv, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "endFrame = pd.concat(li, axis=0, ignore_index=True) #end frame contains all data\n",
    "endFrame.sort_values(by=['time'], ascending=True)   #sorted by time into one time series\n",
    "print(\"for new df: \", endFrame.shape[0])\n",
    "start = endFrame[\"time\"].min()\n",
    "end = endFrame[\"time\"].max()\n",
    "print(\"start: \", start, \" end: \", end)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get indicators: the Ia dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndicators():\n",
    "    return pd.read_csv(\"usIndicatorsFall22-fulls.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read csv for the LOB files of type\n",
    "return a list of all indicator dates, as full readable dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlob(csv):\n",
    "        print(\"GETTING LOB FILE FOR: csv named \",csv)\n",
    "        csv = \"lob_caps/\" + csv\n",
    "        df = pd.read_csv(csv)\n",
    "            # print(\"\\tfor \", type, df.columns)\n",
    "        return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert dates in file names into epoch integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "def convertIndicatorDateToEpoch(original):\n",
    "    # print(\"original \", original) #Thu Aug 11 4:30 AM 2022\n",
    "    re =time.strptime(original, \"%a %b %d %I:%M %p %Y\")\n",
    "    ep = time.mktime(re)\n",
    "    # print(\"TS \", int(ep))   #1660311116579\n",
    "    return int(ep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get full Indicator Announcement data, and dates\n",
    "to help join caps csv to the announcement, on demand, return one list with all econ indicator data plus epoch dates, for integration into the epoch-based data set on caps, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFullIADates():\n",
    "    indicatorData = getIndicators() #indicators file read, access all indicator data per event/announcement\n",
    "    result = []\n",
    "    for row, val in indicatorData.iterrows(): #all indicators\n",
    "        s1 = val['date'].replace(','  , '')\n",
    "        ss = s1.split(\" \")\n",
    "        day  = ss[0][0:3]\n",
    "        mon = ss[1][0:3]\n",
    "        num = ss[2]\n",
    "        hr = val['time']\n",
    "        if int(num) <10:\n",
    "            num = \"0\"+num\n",
    "        yr = ss[3]\n",
    "        l = day + \" \" + mon + \" \" + num #+ \" \" + hr\n",
    "        extendedDateTime = day + \" \" + mon + \" \" + num + \" \" + hr + \" \" +yr\n",
    "        print(\"FOR INDICATOR, DATED: \",extendedDateTime)\n",
    "        IaDict = { \"dictDF\":val, \"epochForIA\":convertIndicatorDateToEpoch( extendedDateTime)} #get the data for the indicator row, then the epoch date\n",
    "        result.append( IaDict) #returns df/caps and the date associated    \n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### integration: set up the viz for caps + indicator\n",
    "iterate the caps by day, then locate an indicator for that day, if one exists, by looking for an indicator whose epoch falls within the range of epoch-based events, that day. \n",
    "\n",
    "vizIAwithCaps: the array used to visualise each day of the indicator, which contains: \n",
    "* data for the indicator (forecast, consensus, actual, date of) [dictDF, pd.DataFrame]\n",
    "* epoch of the indicator, to make an axvline in the chart [epochForIA, int]\n",
    "* capitalization data [capsDF, pd.DataFrame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR INDICATOR, DATED:  Mon Aug 01 6:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Tue Aug 02 6:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Wed Aug 03 6:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Thu Aug 04 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Fri Aug 05 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Wed Aug 10 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Wed Aug 10 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Thu Aug 11 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Fri Aug 12 6:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Tue Aug 16 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Wed Aug 17 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Wed Aug 17 10:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Wed Aug 24 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Fri Aug 26 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Fri Aug 26 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Fri Aug 26 6:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Tue Aug 30 6:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Thu Sep 01 6:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Fri Sep 02 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Tue Sep 06 6:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Wed Sep 07 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Wed Sep 14 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Thu Sep 15 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Fri Sep 16 6:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Tue Sep 20 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Wed Sep 21 10:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Wed Sep 21 10:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Tue Sep 27 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Fri Sep 30 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Fri Sep 30 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Mon Oct 03 6:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Tue Oct 04 6:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Wed Oct 05 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Wed Oct 05 6:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Fri Oct 07 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Wed Oct 12 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Wed Oct 12 10:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Thu Oct 13 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Thu Oct 13 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Fri Oct 14 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Fri Oct 14 6:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Wed Oct 19 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Thu Oct 27 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Fri Oct 28 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Fri Oct 28 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Tue Nov 01 6:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Tue Nov 01 6:00 AM 2022\n",
      "FOR INDICATOR, DATED:  Wed Nov 02 10:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Thu Nov 03 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Fri Nov 04 4:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Thu Nov 10 5:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Thu Nov 10 5:30 AM 2022\n",
      "FOR INDICATOR, DATED:  Fri Nov 11 7:00 AM 2022\n",
      "GETTING LOB FILE FOR: csv named  integrateIndicatorWithCAPS.ipynb\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'lob_caps/integrateIndicatorWithCAPS.ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/stefanbund/ubuntu/m1/iterateAllCps.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/stefanbund/ubuntu/m1/iterateAllCps.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m inds \u001b[39m=\u001b[39m getFullIADates()  \u001b[39m#all dates for indicators, as epochs inds[i][dictDF] / epochForIA\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/stefanbund/ubuntu/m1/iterateAllCps.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(csvFileList)):\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/stefanbund/ubuntu/m1/iterateAllCps.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     tempDF \u001b[39m=\u001b[39m getlob(csvFileList[i])         \u001b[39m#get lob stats for that day \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/stefanbund/ubuntu/m1/iterateAllCps.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     capsWithIndicatorDict \u001b[39m=\u001b[39m {}\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/stefanbund/ubuntu/m1/iterateAllCps.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mmin\u001b[39m \u001b[39m=\u001b[39m tempDF[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmin()\n",
      "\u001b[1;32m/home/stefanbund/ubuntu/m1/iterateAllCps.ipynb Cell 14\u001b[0m in \u001b[0;36mgetlob\u001b[0;34m(csv)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/stefanbund/ubuntu/m1/iterateAllCps.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGETTING LOB FILE FOR: csv named \u001b[39m\u001b[39m\"\u001b[39m,csv)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/stefanbund/ubuntu/m1/iterateAllCps.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m csv \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlob_caps/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m csv\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/stefanbund/ubuntu/m1/iterateAllCps.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(csv)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/stefanbund/ubuntu/m1/iterateAllCps.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# print(\"\\tfor \", type, df.columns)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/stefanbund/ubuntu/m1/iterateAllCps.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/pandas/io/parsers/readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 934\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1219\u001b[0m     f,\n\u001b[1;32m   1220\u001b[0m     mode,\n\u001b[1;32m   1221\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1223\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1224\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1225\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1226\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1227\u001b[0m )\n\u001b[1;32m   1228\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/pandas/io/common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    787\u001b[0m             handle,\n\u001b[1;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    792\u001b[0m         )\n\u001b[1;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lob_caps/integrateIndicatorWithCAPS.ipynb'"
     ]
    }
   ],
   "source": [
    "vizIAwithCaps = [] #a list of capitalization dataframes, with respecitve indicators\n",
    "\n",
    "inds = getFullIADates()  #all dates for indicators, as epochs inds[i][dictDF] / epochForIA\n",
    "for i in range(len(csvFileList)):\n",
    "    tempDF = getlob(csvFileList[i])         #get lob stats for that day \n",
    "    capsWithIndicatorDict = {}\n",
    "    min = tempDF['time'].min()\n",
    "    max = tempDF['time'].max()              #respective range of dates, as epoch\n",
    "    print(\"for epoch period \", min , \" --> \", max)\n",
    "    for i in range(len(inds)):              #scan indicators for a date that falls inside the min/max range of time\n",
    "        # if inds[i]['epochForIA'] <= max and inds[i]['epochForIA'] >= min:\n",
    "        if inds[i]['epochForIA'] in range(min, max):\n",
    "            print(\"Economic indicator for caps is \", inds[i]['dictDF']['indicator'])\n",
    "            print(\"occuring at time \", inds[i]['epochForIA'])\n",
    "            capsWithIndicatorDict[\"indicatorDF\"] = inds[i]['dictDF']            #indicator's data frame row (series?)\n",
    "            capsWithIndicatorDict['indicatorEpoch'] = inds[i]['epochForIA']     #epoch for indicator, during the day of the caps file \n",
    "            capsWithIndicatorDict['capsDF'] = tempDF                            #dataframe for the csv, for graphing \n",
    "            print(capsWithIndicatorDict)\n",
    "            vizIAwithCaps.append(capsWithIndicatorDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def demarcateByAnnounceTime(dfArray): #indicatorDF, indicatorEpoch, capsDF\n",
    "    \n",
    "    for i in range(len(dfArray)):\n",
    "        #if isinstance(dfArray[i], dict):                \n",
    "        print(\"start time: \", dfArray[i][\"capsDF\"][\"time\"].min())\n",
    "        print(\"end time: \", dfArray[i][\"capsDF\"][\"time\"].max())\n",
    "        print(\"date of data: \", dfArray[i]['indicatorDF'][\"date\"], \"\\n\")\n",
    "        data1 = dfArray[i][\"capsDF\"]['mp']\n",
    "        data2 = dfArray[i][\"capsDF\"]['bc']\n",
    "        t= dfArray[i][\"capsDF\"]['time']\n",
    "        ai = dfArray[i]['indicatorEpoch']              #[\"time\"]\n",
    "        fig, ax1 = plt.subplots()\n",
    "        tt = i + 1\n",
    "\n",
    "        color = 'tab:red'\n",
    "        ax1.set_xlabel('time (s)')\n",
    "        ax1.set_ylabel('price, AVAX', color=color)\n",
    "        ax1.plot(t, data1, color=color)\n",
    "        ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "        ax2 = ax1.twinx()                        # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "        color = 'tab:blue'\n",
    "        ax2.set_ylabel('buy capitalization', color=color)  # we already handled the x-label with ax1\n",
    "        ax2.plot(t, data2, color=color)\n",
    "        ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "        fig.tight_layout()                      # otherwise the right y-label is slightly clipped\n",
    "        # e = dfArray[i][\"capsDF\"]['time'].loc[0]     #datetime.datetime.fromtimestamp(\n",
    "        # comb = e ,\" Buy Cap versus Price\"       #.strftime('%m-%d')\n",
    "        titleF = \"date of data: \" + dfArray[i]['indicatorDF'][\"date\"]\n",
    "        plt.title(titleF)\n",
    "        plt.axvline(x=ai, color='black', linestyle='-')\n",
    "        plt.show()\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "demarcateByAnnounceTime( vizIAwithCaps)  #send the collected \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "                                # print(type(inds), inds.columns)\n",
    "def genDatesForIndicators():\n",
    "    inds = getIndicators() \n",
    "    ret = []               \n",
    "    for key, val in inds.iterrows():\n",
    "                                    # print(key, val[\"date\"], val[\"time\"])\n",
    "        s1 = val['date'].replace(','  , '')\n",
    "        ss = s1.split(\" \")\n",
    "        day  = ss[0][0:3]\n",
    "        mon = ss[1][0:3]\n",
    "        num = ss[2]\n",
    "        hr = val['time']\n",
    "        if int(num) <10:\n",
    "            num = \"0\"+num\n",
    "        yr = ss[3]\n",
    "        l = day + \" \" + mon + \" \" + num #+ \" \" + hr\n",
    "        extendedDateTime = day + \" \" + mon + \" \" + num + \" \" + hr + \" \" +yr\n",
    "                            # print(\"FOR INDICATOR, DATED: \",extendedDateTime)\n",
    "        d = convertIndicatorDateToEpoch(extendedDateTime)\n",
    "        # print(d)\n",
    "        ret.append(np.int64(d))\n",
    "    return ret\n",
    "        \n",
    "dateArr = genDatesForIndicators()\n",
    "for i in range(len(dateArr)):\n",
    "    print(type(dateArr[i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "endFrame: collected time series, several months, 111K+ events\n",
    "\n",
    "dateArr: list of all dates, as epochs for all indicators (dates only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'endFrame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/stefanbund/ubuntu/m1/iterateAllCps.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/stefanbund/ubuntu/m1/iterateAllCps.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m l \u001b[39m=\u001b[39m endFrame[(endFrame[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1668178800\u001b[39m ) \u001b[39m&\u001b[39m (endFrame[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m1664578800\u001b[39m   )] \u001b[39m#1664578800  -->  1668178800\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/stefanbund/ubuntu/m1/iterateAllCps.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(l\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'endFrame' is not defined"
     ]
    }
   ],
   "source": [
    "l = endFrame[(endFrame['time'] <= 1668178800 ) & (endFrame['time'] > 1664578800   )] #1664578800  -->  1668178800\n",
    "print(l.shape[0])\n",
    "\n",
    "# for key, val in endFrame.iterrows():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresh = ((1000 * 60) * 60 ) * 1\n",
    "# print(\"threshold minus gate: \", thresh)\n",
    "# print(endFrame.dtypes)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iterate all anouncement times, associate 1,000 data points before then after each, then calculate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3e22fbf24de83286095bc3b5210627f6bc981651d6552786864646d5785863e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
